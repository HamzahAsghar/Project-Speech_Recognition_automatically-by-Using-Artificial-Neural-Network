This project implements an Automatic Speech Recognition (ASR) system using a combination of a 2D Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Connectionist Temporal Classification (CTC) loss. The model converts spoken language into text, aiming to improve accuracy in noisy or accented speech scenarios.

Key Features
1. 2D CNN: Extracts features from the input audio spectrogram.
2. RNN: Captures temporal dependencies in the speech data.
3. CTC Loss: Enables mapping of variable-length input sequences to text without pre-aligned labels.

Applications
1. Speech-to-text transcription
2. Phoneme and word recognition
3. End-to-end speech recognition systems

Keywords
Neural Network, CNN, RNN, CTC, Speech Recognition, Phoneme Recognition
